{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6c4cd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:30.703323Z",
     "iopub.status.busy": "2025-05-18T04:48:30.703105Z",
     "iopub.status.idle": "2025-05-18T04:48:30.709329Z",
     "shell.execute_reply": "2025-05-18T04:48:30.708751Z"
    },
    "papermill": {
     "duration": 0.0119,
     "end_time": "2025-05-18T04:48:30.710414",
     "exception": false,
     "start_time": "2025-05-18T04:48:30.698514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't forget to change the dataset argument\n"
     ]
    }
   ],
   "source": [
    "LOG_PATH = '/kaggle/input/rl-prompt-results-part-2-rio/all_outputs_sst2.log'\n",
    "print(\"Don't forget to change the dataset argument\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd39a2e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:30.717978Z",
     "iopub.status.busy": "2025-05-18T04:48:30.717789Z",
     "iopub.status.idle": "2025-05-18T04:48:32.181455Z",
     "shell.execute_reply": "2025-05-18T04:48:32.180897Z"
    },
    "papermill": {
     "duration": 1.468927,
     "end_time": "2025-05-18T04:48:32.182959",
     "exception": false,
     "start_time": "2025-05-18T04:48:30.714032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5f2e8c",
   "metadata": {
    "papermill": {
     "duration": 0.003415,
     "end_time": "2025-05-18T04:48:32.190171",
     "exception": false,
     "start_time": "2025-05-18T04:48:32.186756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Experiments Data Getter: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde8bda5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:32.197592Z",
     "iopub.status.busy": "2025-05-18T04:48:32.197281Z",
     "iopub.status.idle": "2025-05-18T04:48:34.574271Z",
     "shell.execute_reply": "2025-05-18T04:48:34.573666Z"
    },
    "papermill": {
     "duration": 2.382017,
     "end_time": "2025-05-18T04:48:34.575501",
     "exception": false,
     "start_time": "2025-05-18T04:48:32.193484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "log_file = LOG_PATH\n",
    "\n",
    "step_pattern = re.compile(r'^(\\d+)\\s+\\|')\n",
    "reward_pattern = re.compile(r'([-+]?\\d*\\.\\d+|\\d+)')\n",
    "accuracy_pattern = re.compile(r'Accuracy:\\s*([-+]?\\d*\\.\\d+|\\d+)')\n",
    "\n",
    "steps = []\n",
    "rewards = []\n",
    "accuracy = []\n",
    "prompts = []\n",
    "\n",
    "with open(log_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "current_step = None\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    step_match = step_pattern.match(line)\n",
    "    if step_match:\n",
    "        current_step = int(step_match.group(1))\n",
    "\n",
    "    if \"Our Prompt:\" in line:\n",
    "        next_line = lines[i + 1].strip()\n",
    "        prev_line = lines[i - 1].strip()\n",
    "\n",
    "        accuracy_match = accuracy_pattern.search(prev_line)\n",
    "        numbers = reward_pattern.findall(next_line)\n",
    "\n",
    "        if accuracy_match and numbers and current_step is not None:\n",
    "            acc_value = float(accuracy_match.group(1))\n",
    "            reward_value = float(numbers[-1])\n",
    "\n",
    "            steps.append(current_step)\n",
    "            rewards.append(reward_value)\n",
    "            accuracy.append(acc_value)\n",
    "            prompts.append(next_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d34cc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:34.583727Z",
     "iopub.status.busy": "2025-05-18T04:48:34.583479Z",
     "iopub.status.idle": "2025-05-18T04:48:34.652305Z",
     "shell.execute_reply": "2025-05-18T04:48:34.651764Z"
    },
    "papermill": {
     "duration": 0.074261,
     "end_time": "2025-05-18T04:48:34.653508",
     "exception": false,
     "start_time": "2025-05-18T04:48:34.579247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INTERVAL = 600\n",
    "\n",
    "starts = 0\n",
    "end = starts + INTERVAL\n",
    "\n",
    "seed_best_prompts = []\n",
    "\n",
    "validation_dfs = {}\n",
    "\n",
    "while end <= len(steps):\n",
    "    interval_acc = accuracy[starts:end]\n",
    "    interval_prompts = prompts[starts:end]\n",
    "    interval_steps = steps[starts:end]\n",
    "    interval_rewards = rewards[starts:end]\n",
    "    seed = starts // INTERVAL\n",
    "\n",
    "    max_idx = interval_acc.index(max(interval_acc))\n",
    "    best_prompt = interval_prompts[max_idx]\n",
    "    seed_best_prompts.append((seed, max(interval_acc), best_prompt))\n",
    "\n",
    "    values = {\n",
    "        'step': interval_steps,\n",
    "        'accuracy': interval_acc,\n",
    "        'rewards': interval_rewards,\n",
    "        'prompts': interval_prompts,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(values)\n",
    "    validation_dfs[seed] = df\n",
    "    df.to_csv(f\"validation_results_{seed}.csv\",index=False)\n",
    "\n",
    "    starts = end\n",
    "    end = starts + INTERVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7908d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:34.660855Z",
     "iopub.status.busy": "2025-05-18T04:48:34.660588Z",
     "iopub.status.idle": "2025-05-18T04:48:34.665001Z",
     "shell.execute_reply": "2025-05-18T04:48:34.664213Z"
    },
    "papermill": {
     "duration": 0.009175,
     "end_time": "2025-05-18T04:48:34.666022",
     "exception": false,
     "start_time": "2025-05-18T04:48:34.656847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0: Max Accuracy = 0.8125\n",
      "Prompt: ['Absolutelyibly'] 57.354087829589844\n",
      "--------------------------------------------------\n",
      "Seed 1: Max Accuracy = 0.7812\n",
      "Prompt: ['Sounds profoundly'] 85.52429962158203\n",
      "--------------------------------------------------\n",
      "Seed 2: Max Accuracy = 0.7500\n",
      "Prompt: ['absolute overall'] 66.77888488769531\n",
      "--------------------------------------------------\n",
      "Seed 3: Max Accuracy = 0.8750\n",
      "Prompt: [' extremely extremely'] 71.49598693847656\n",
      "--------------------------------------------------\n",
      "Seed 4: Max Accuracy = 0.9062\n",
      "Prompt: ['itivenessitiveness'] 80.28788757324219\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print best prompt (highest accuracy) for each seed\n",
    "for seed, acc, prompt in seed_best_prompts:\n",
    "    print(f\"Seed {seed}: Max Accuracy = {acc:.4f}\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8cd3363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:34.673844Z",
     "iopub.status.busy": "2025-05-18T04:48:34.673418Z",
     "iopub.status.idle": "2025-05-18T04:48:34.677946Z",
     "shell.execute_reply": "2025-05-18T04:48:34.677330Z"
    },
    "papermill": {
     "duration": 0.009534,
     "end_time": "2025-05-18T04:48:34.679021",
     "exception": false,
     "start_time": "2025-05-18T04:48:34.669487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Absolutelyibly', 'Sounds profoundly', 'absolute overall', ' extremely extremely', 'itivenessitiveness']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "best_prompt_words = []\n",
    "\n",
    "for _, _, raw_prompt in seed_best_prompts:\n",
    "    try:\n",
    "        bracket_content = raw_prompt.split(']')[0] + ']'\n",
    "        prompt_list = ast.literal_eval(bracket_content)\n",
    "        if isinstance(prompt_list, list) and len(prompt_list) > 0:\n",
    "            best_prompt_words.append(prompt_list[0])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(best_prompt_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b660c",
   "metadata": {
    "papermill": {
     "duration": 0.003219,
     "end_time": "2025-05-18T04:48:34.685744",
     "exception": false,
     "start_time": "2025-05-18T04:48:34.682525",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Experiments Data Getter: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7d1157",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:34.693110Z",
     "iopub.status.busy": "2025-05-18T04:48:34.692936Z",
     "iopub.status.idle": "2025-05-18T04:48:37.402097Z",
     "shell.execute_reply": "2025-05-18T04:48:37.401184Z"
    },
    "papermill": {
     "duration": 2.714231,
     "end_time": "2025-05-18T04:48:37.403327",
     "exception": false,
     "start_time": "2025-05-18T04:48:34.689096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 1.58 hours (95.05 minutes)\n",
      "\n",
      "Peak GPU memory usage: 1482.08 MB (1.45 GB)\n",
      "\n",
      "Total training time: 1.54 hours (92.11 minutes)\n",
      "\n",
      "Peak GPU memory usage: 1456.16 MB (1.42 GB)\n",
      "\n",
      "Total training time: 1.37 hours (82.27 minutes)\n",
      "\n",
      "Peak GPU memory usage: 1424.58 MB (1.39 GB)\n",
      "\n",
      "Total training time: 1.53 hours (91.51 minutes)\n",
      "\n",
      "Peak GPU memory usage: 1449.80 MB (1.42 GB)\n",
      "\n",
      "Total training time: 1.43 hours (85.94 minutes)\n",
      "\n",
      "Peak GPU memory usage: 1424.88 MB (1.39 GB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_file = LOG_PATH\n",
    "\n",
    "all_rewards = {}\n",
    "all_accuracy = {}\n",
    "\n",
    "header_pattern = re.compile(r'^(\\d+)\\s*\\|')\n",
    "reward_pattern = re.compile(r'Reward:\\s*([-+]?\\d*\\.\\d+|\\d+)')\n",
    "accuracy_pattern = re.compile(r'Accuracy:\\s*([-+]?\\d*\\.\\d+|\\d+)')\n",
    "\n",
    "with open(log_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "current_step = None\n",
    "seed = -1\n",
    "\n",
    "for line in lines:\n",
    "    if 'Task LM' in line:\n",
    "        seed += 1\n",
    "        all_rewards[seed] = {}\n",
    "        all_accuracy[seed] = {}\n",
    "        continue\n",
    "    \n",
    "    header_match = header_pattern.match(line)\n",
    "    if header_match:\n",
    "        current_step = int(header_match.group(1))\n",
    "    \n",
    "    if \"Reward:\" in line:\n",
    "        reward_match = reward_pattern.search(line)\n",
    "        if reward_match:\n",
    "            reward_value = float(reward_match.group(1))\n",
    "            if current_step is not None:\n",
    "                all_rewards[seed].setdefault(current_step, []).append(reward_value)\n",
    "\n",
    "    if \"Accuracy:\" in line:\n",
    "        accuracy_match = accuracy_pattern.search(line)\n",
    "        if accuracy_match:\n",
    "            accuracy_value = float(accuracy_match.group(1))\n",
    "            if current_step is not None:\n",
    "                all_accuracy[seed].setdefault(current_step, []).append(accuracy_value)\n",
    "\n",
    "    if 'Total training time' in line:\n",
    "        print(line)\n",
    "\n",
    "    if 'Peak GPU' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c07888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:37.411953Z",
     "iopub.status.busy": "2025-05-18T04:48:37.411717Z",
     "iopub.status.idle": "2025-05-18T04:48:38.247098Z",
     "shell.execute_reply": "2025-05-18T04:48:38.246521Z"
    },
    "papermill": {
     "duration": 0.840991,
     "end_time": "2025-05-18T04:48:38.248380",
     "exception": false,
     "start_time": "2025-05-18T04:48:37.407389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_results_dfs = {}\n",
    "\n",
    "for seed, data in all_rewards.items():\n",
    "    steps = sorted(data.keys())\n",
    "    means = [np.mean(data[step]) for step in steps]\n",
    "    stds  = [np.std(data[step]) for step in steps]\n",
    "\n",
    "    values = {\n",
    "        'step': steps,\n",
    "        'reward_mean': means,\n",
    "        'reward_std': stds\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(values)\n",
    "    training_results_dfs[seed] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3053ea9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:38.256715Z",
     "iopub.status.busy": "2025-05-18T04:48:38.256467Z",
     "iopub.status.idle": "2025-05-18T04:48:39.166964Z",
     "shell.execute_reply": "2025-05-18T04:48:39.166380Z"
    },
    "papermill": {
     "duration": 0.916058,
     "end_time": "2025-05-18T04:48:39.168344",
     "exception": false,
     "start_time": "2025-05-18T04:48:38.252286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for seed, data in all_accuracy.items():\n",
    "    steps = sorted(data.keys())\n",
    "    means = [np.mean(data[step]) for step in steps]\n",
    "    stds  = [np.std(data[step]) for step in steps]\n",
    "\n",
    "    df = training_results_dfs[seed]\n",
    "    df['accuracy_mean'] = means\n",
    "    df['accuracy_stds'] = stds\n",
    "    df.to_csv(f\"training_results_{seed}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee61a6f",
   "metadata": {
    "papermill": {
     "duration": 0.003719,
     "end_time": "2025-05-18T04:48:39.176554",
     "exception": false,
     "start_time": "2025-05-18T04:48:39.172835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Environment Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb66b81f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:39.184254Z",
     "iopub.status.busy": "2025-05-18T04:48:39.183893Z",
     "iopub.status.idle": "2025-05-18T04:48:39.187227Z",
     "shell.execute_reply": "2025-05-18T04:48:39.186522Z"
    },
    "papermill": {
     "duration": 0.008593,
     "end_time": "2025-05-18T04:48:39.188485",
     "exception": false,
     "start_time": "2025-05-18T04:48:39.179892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a42717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:39.196477Z",
     "iopub.status.busy": "2025-05-18T04:48:39.196274Z",
     "iopub.status.idle": "2025-05-18T04:48:52.314704Z",
     "shell.execute_reply": "2025-05-18T04:48:52.313830Z"
    },
    "papermill": {
     "duration": 13.123685,
     "end_time": "2025-05-18T04:48:52.315887",
     "exception": false,
     "start_time": "2025-05-18T04:48:39.192202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = \"/kaggle/conda\"\n",
    "!mkdir -p $root_dir\n",
    "!wget -q --show-progress https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "!bash Miniconda3-latest-Linux-x86_64.sh -b -p $root_dir/miniconda3 -f\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3e3cef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:48:52.324239Z",
     "iopub.status.busy": "2025-05-18T04:48:52.323957Z",
     "iopub.status.idle": "2025-05-18T04:49:01.925056Z",
     "shell.execute_reply": "2025-05-18T04:49:01.924086Z"
    },
    "papermill": {
     "duration": 9.606659,
     "end_time": "2025-05-18T04:49:01.926227",
     "exception": false,
     "start_time": "2025-05-18T04:48:52.319568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!$root_dir/miniconda3/bin/conda create --name my_env python=3.10 -y\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c43bdd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:49:01.935098Z",
     "iopub.status.busy": "2025-05-18T04:49:01.934880Z",
     "iopub.status.idle": "2025-05-18T04:49:08.369880Z",
     "shell.execute_reply": "2025-05-18T04:49:08.369149Z"
    },
    "papermill": {
     "duration": 6.440616,
     "end_time": "2025-05-18T04:49:08.371187",
     "exception": false,
     "start_time": "2025-05-18T04:49:01.930571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'rl-prompt'...\r\n",
      "remote: Enumerating objects: 1813, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (661/661), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (385/385), done.\u001b[K\r\n",
      "remote: Total 1813 (delta 381), reused 466 (delta 273), pack-reused 1152 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (1813/1813), 83.59 MiB | 28.71 MiB/s, done.\r\n",
      "Resolving deltas: 100% (790/790), done.\r\n",
      "Updating files: 100% (291/291), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/malifalhakim/rl-prompt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521d21fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:49:08.383207Z",
     "iopub.status.busy": "2025-05-18T04:49:08.382585Z",
     "iopub.status.idle": "2025-05-18T04:49:08.388868Z",
     "shell.execute_reply": "2025-05-18T04:49:08.388277Z"
    },
    "papermill": {
     "duration": 0.013181,
     "end_time": "2025-05-18T04:49:08.389981",
     "exception": false,
     "start_time": "2025-05-18T04:49:08.376800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/rl-prompt\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/rl-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5a25840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:49:08.400812Z",
     "iopub.status.busy": "2025-05-18T04:49:08.400578Z",
     "iopub.status.idle": "2025-05-18T04:51:05.351125Z",
     "shell.execute_reply": "2025-05-18T04:51:05.350273Z"
    },
    "papermill": {
     "duration": 116.95758,
     "end_time": "2025-05-18T04:51:05.352647",
     "exception": false,
     "start_time": "2025-05-18T04:49:08.395067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the CUDA version variable\n",
    "CUDA_VERSION = 'cu118'\n",
    "\n",
    "# 1. Install PyTorch with matching CUDA version\n",
    "!source $root_dir/miniconda3/bin/activate my_env; pip install torch==2.6.0+{CUDA_VERSION} \\\n",
    "--extra-index-url https://download.pytorch.org/whl/{CUDA_VERSION}\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b744d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:51:05.364393Z",
     "iopub.status.busy": "2025-05-18T04:51:05.364158Z",
     "iopub.status.idle": "2025-05-18T04:51:34.493915Z",
     "shell.execute_reply": "2025-05-18T04:51:34.493180Z"
    },
    "papermill": {
     "duration": 29.137038,
     "end_time": "2025-05-18T04:51:34.495231",
     "exception": false,
     "start_time": "2025-05-18T04:51:05.358193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!source $root_dir/miniconda3/bin/activate my_env; pip install -e .\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a6c575",
   "metadata": {
    "papermill": {
     "duration": 0.004953,
     "end_time": "2025-05-18T04:51:34.505732",
     "exception": false,
     "start_time": "2025-05-18T04:51:34.500779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3210e3e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:51:34.517066Z",
     "iopub.status.busy": "2025-05-18T04:51:34.516509Z",
     "iopub.status.idle": "2025-05-18T04:51:34.521891Z",
     "shell.execute_reply": "2025-05-18T04:51:34.521157Z"
    },
    "papermill": {
     "duration": 0.012413,
     "end_time": "2025-05-18T04:51:34.523017",
     "exception": false,
     "start_time": "2025-05-18T04:51:34.510604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/rl-prompt/examples/few-shot-classification/evaluation\n"
     ]
    }
   ],
   "source": [
    "%cd examples/few-shot-classification/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d69ace88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:51:34.533795Z",
     "iopub.status.busy": "2025-05-18T04:51:34.533578Z",
     "iopub.status.idle": "2025-05-18T04:51:34.537105Z",
     "shell.execute_reply": "2025-05-18T04:51:34.536555Z"
    },
    "papermill": {
     "duration": 0.009969,
     "end_time": "2025-05-18T04:51:34.538067",
     "exception": false,
     "start_time": "2025-05-18T04:51:34.528098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"prompts.txt\", \"w\") as f:\n",
    "    for prompt in best_prompt_words:\n",
    "        f.write(prompt + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ba0392f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:51:34.548961Z",
     "iopub.status.busy": "2025-05-18T04:51:34.548784Z",
     "iopub.status.idle": "2025-05-18T04:54:42.036265Z",
     "shell.execute_reply": "2025-05-18T04:54:42.035488Z"
    },
    "papermill": {
     "duration": 187.500636,
     "end_time": "2025-05-18T04:54:42.043720",
     "exception": false,
     "start_time": "2025-05-18T04:51:34.543084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "Running evaluation with prompt: Absolutelyibly\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: distilroberta-base\n",
      "is_mask_lm: null\n",
      "prompt: Absolutelyibly\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: distilroberta-base\n",
      "[2025-05-18 04:51:41,646][huggingface_hub.file_download][WARNING] - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "\u001b[31mprompt: Absolutelyibly, accuracy: 0.794069230556488\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-base\n",
      "is_mask_lm: null\n",
      "prompt: Absolutelyibly\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-base\n",
      "[2025-05-18 04:51:52,739][huggingface_hub.file_download][WARNING] - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "\u001b[31mprompt: Absolutelyibly, accuracy: 0.7775947451591492\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-large\n",
      "is_mask_lm: null\n",
      "prompt: Absolutelyibly\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-large\n",
      "[2025-05-18 04:52:05,712][huggingface_hub.file_download][WARNING] - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "\u001b[31mprompt: Absolutelyibly, accuracy: 0.8605161905288696\u001b[0m\n",
      "----------------------------------------------\n",
      "Running evaluation with prompt: Sounds profoundly\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: distilroberta-base\n",
      "is_mask_lm: null\n",
      "prompt: Sounds profoundly\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: distilroberta-base\n",
      "\u001b[31mprompt: Sounds profoundly, accuracy: 0.833058774471283\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-base\n",
      "is_mask_lm: null\n",
      "prompt: Sounds profoundly\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-base\n",
      "\u001b[31mprompt: Sounds profoundly, accuracy: 0.8841295838356018\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-large\n",
      "is_mask_lm: null\n",
      "prompt: Sounds profoundly\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-large\n",
      "\u001b[31mprompt: Sounds profoundly, accuracy: 0.8390994071960449\u001b[0m\n",
      "----------------------------------------------\n",
      "Running evaluation with prompt: absolute overall\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: distilroberta-base\n",
      "is_mask_lm: null\n",
      "prompt: absolute overall\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: distilroberta-base\n",
      "\u001b[31mprompt: absolute overall, accuracy: 0.7918726205825806\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-base\n",
      "is_mask_lm: null\n",
      "prompt: absolute overall\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-base\n",
      "\u001b[31mprompt: absolute overall, accuracy: 0.7682592272758484\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-large\n",
      "is_mask_lm: null\n",
      "prompt: absolute overall\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-large\n",
      "\u001b[31mprompt: absolute overall, accuracy: 0.8374519348144531\u001b[0m\n",
      "----------------------------------------------\n",
      "Running evaluation with prompt:  extremely extremely\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: distilroberta-base\n",
      "is_mask_lm: null\n",
      "prompt: ' extremely extremely'\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: distilroberta-base\n",
      "\u001b[31mprompt:  extremely extremely, accuracy: 0.8220757842063904\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-base\n",
      "is_mask_lm: null\n",
      "prompt: ' extremely extremely'\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-base\n",
      "\u001b[31mprompt:  extremely extremely, accuracy: 0.8550246953964233\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-large\n",
      "is_mask_lm: null\n",
      "prompt: ' extremely extremely'\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-large\n",
      "\u001b[31mprompt:  extremely extremely, accuracy: 0.8951125741004944\u001b[0m\n",
      "----------------------------------------------\n",
      "Running evaluation with prompt: itivenessitiveness\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: distilroberta-base\n",
      "is_mask_lm: null\n",
      "prompt: itivenessitiveness\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: distilroberta-base\n",
      "\u001b[31mprompt: itivenessitiveness, accuracy: 0.7649643421173096\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-base\n",
      "is_mask_lm: null\n",
      "prompt: itivenessitiveness\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-base\n",
      "\u001b[31mprompt: itivenessitiveness, accuracy: 0.6342669129371643\u001b[0m\n",
      "\u001b[31mnum_shots: 16\n",
      "base_path: ../data\n",
      "dataset: sst-2\n",
      "dataset_seed: 0\n",
      "task_lm: roberta-large\n",
      "is_mask_lm: null\n",
      "prompt: itivenessitiveness\n",
      "\u001b[0m\n",
      "Test Size 1821\n",
      "Examples: {'source_texts': ['no movement , no yuks , not much of anything .', \"a gob of drivel so sickly sweet , even the eager consumers of moore 's pasteurized ditties will retch it up like rancid crème brûlée .\", 'gangs of new york is an unapologetic mess , whose only saving grace is that it ends by blowing just about everything up .', 'we never really feel involved with the story , as all of its ideas remain just that : abstract ideas .', \"this is one of polanski 's best films .\"], 'class_labels': [0, 0, 0, 0, 1]}\n",
      "Task LM: roberta-large\n",
      "\u001b[31mprompt: itivenessitiveness, accuracy: 0.676551342010498\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source /kaggle/conda/miniconda3/bin/activate my_env\n",
    "\n",
    "while IFS= read -r prompt; do\n",
    "    echo \"----------------------------------------------\"\n",
    "    echo \"Running evaluation with prompt: $prompt\"\n",
    "    python run_eval.py dataset=sst-2 task_lm=distilroberta-base \"prompt=\\\"${prompt}\\\"\"\n",
    "    python run_eval.py dataset=sst-2 task_lm=roberta-base \"prompt=\\\"${prompt}\\\"\"\n",
    "    python run_eval.py dataset=sst-2 task_lm=roberta-large \"prompt=\\\"${prompt}\\\"\"\n",
    "done < prompts.txt"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7448425,
     "sourceId": 11853781,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7448496,
     "sourceId": 11853893,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7119255,
     "sourceId": 11853958,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7448605,
     "sourceId": 11854059,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 376.289665,
   "end_time": "2025-05-18T04:54:42.766810",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-18T04:48:26.477145",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
