# Few-Shot Classification Config
defaults:
 - base_fsc
 - _self_

# Data
num_shots: 16
base_path: "./data"
dataset: "sst-2"
dataset_seed: 0

# Reward
task_lm: "distilroberta-base"

# Single Prompt Model
prompt_length: 2
prompt_train_batch_size: 16
prompt_infer_batch_size: 1

# Module (Algorithm) config
reward_shaping_old_min: 0
reward_shaping_old_max: 1
reward_shaping_new_min: 0
reward_shaping_new_max: 5
top_k: 256
gamma: 0.99

# Trainer
max_train_steps: 6000
train_shuffle: false
eval_steps: 10
save_steps: 100
learning_rate: 5e-5
random_seed: null

# Algorithm "ppo-onpolicy" (ppo), "q-onpolicy" (q), or "sql-onpolicy" (sql)
training_mode: "ppo-onpolicy"